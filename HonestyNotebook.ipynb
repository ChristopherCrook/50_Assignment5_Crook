{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HonestyNotebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVkwUlbjBrs02LbmXPcqfI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChristopherCrook/50_Assignment5_Crook/blob/main/HonestyNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Overview\n",
        "This project will attempt to predict a correlation between a person's religion and whether they display personality traits indicitive of Machiavellian tendencies. Included in this prediction will be whether the person considers themselves more introverted or extroverted.\n",
        "\n",
        "## Data Set\n",
        "Machivallianism Test on Kaggle\n",
        "\n",
        "## Performance Measures\n",
        "This will be based on a percentage of people with more honest traits and what their religious preference is along with whether they identify as being more reserved or extroverted."
      ],
      "metadata": {
        "id": "bmN_oGKks2wN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "3FmQ0oc6e3fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tables and visualizations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#machine learning\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, StandardScaler, OrdinalEncoder\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn import config_context\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "Zv-9lMGifAuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://github.com/vanderbilt-ml/50-Crook-mlproj-Honesty/blob/main/data.csv?raw=true', delimiter='\\t')\n",
        "data.info()"
      ],
      "metadata": {
        "id": "MJesBcAlfRZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute Scores, Delete Columns and Add Scores columns\n",
        "## We don't necessarily care about the questions themselves, but we do care about the total score of all questions, so we need to calculate them. Values should be between 20-100."
      ],
      "metadata": {
        "id": "2laaMQnWd6Nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare the variables we need\n",
        "scores = []\n",
        "current_score = 0\n",
        "current_column = \"\"\n",
        "\n",
        "prefix = \"Q\"\n",
        "a_suffix = \"A\"\n",
        "i_suffix = \"I\"\n",
        "e_suffix = \"E\"\n",
        "\n",
        "# Begin our loop by iterating through the rows\n",
        "for i in range(len(data)) :\n",
        "  # Zeroize the current_score\n",
        "  current_score = 0\n",
        "  # Add the answers to questions in each row\n",
        "  for x in range(20):\n",
        "    current_column = prefix + str(x+1) + a_suffix\n",
        "    current_score = current_score + data.loc[i, current_column]\n",
        "  # Add the score to the list\n",
        "  scores.append(current_score)\n",
        "\n",
        "# Print, just so we know everything went okay (Uncomment only if needed)\n",
        "#for i in range(len(scores)) :\n",
        "#  print(scores[i])\n",
        "\n",
        "# Check our scores to ensure that we don't have any crazy values\n",
        "outliers = 0\n",
        "for i in range(len(scores)) :\n",
        "  if (i < 20 or i > 100) :\n",
        "    outliers = outliers + 1\n",
        "\n",
        "print(\"Outliers: \" + str(outliers))"
      ],
      "metadata": {
        "id": "iADjG3m0eCM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can remove the columns we don't need\n",
        "current_a = \"\"\n",
        "current_i = \"\"\n",
        "current_e = \"\"\n",
        "\n",
        "for i in range(20) :\n",
        "  current_a = prefix + str(i+1) + a_suffix\n",
        "  current_i = prefix + str(i+1) + i_suffix\n",
        "  current_e = prefix + str(i+1) + e_suffix\n",
        "  #print(current_a + \" \" + current_i + \" \" + current_e)\n",
        "  data.drop([current_a], inplace=True, axis=1)\n",
        "  data.drop([current_i], inplace=True, axis=1)\n",
        "  data.drop([current_e], inplace=True, axis=1)\n",
        "\n",
        "# Now add the Scores column\n",
        "data['Score'] = scores"
      ],
      "metadata": {
        "id": "IeRe4owbjlID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the data after the conversion\n",
        "print(data)"
      ],
      "metadata": {
        "id": "CsWqZZ9Ygv4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "oTdLNykq9Yda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at a graph of the data first\n",
        "sns.pairplot(data, hue='religion')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ePgbdn_gChr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the Data"
      ],
      "metadata": {
        "id": "3fu9X0PvhuLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_column = 'religion'\n",
        "random_seed = 2435\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=class_column), data[class_column],\n",
        "                                                   test_size=0.2, random_state=random_seed, stratify=data[class_column])"
      ],
      "metadata": {
        "id": "-WgSOTqxhwVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sanity Check"
      ],
      "metadata": {
        "id": "pDo-qO3giGFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X Train\n",
        "print('On X train: ')\n",
        "print('X train dimensions: ', X_train.shape)\n",
        "display(X_train.head())\n",
        "\n",
        "# X test\n",
        "print('\\nOn X test: ')\n",
        "print('X test dimensions: ', X_test.shape)\n",
        "display(X_test.head())"
      ],
      "metadata": {
        "id": "2dISGerGhwZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Pipelines"
      ],
      "metadata": {
        "id": "kPi81VhH-rmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#individual pipelines for differing datatypes\n",
        "cat_pipeline = Pipeline(steps=[('cat_impute', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
        "                               ('onehot_cat', OneHotEncoder(drop='if_binary'))])\n",
        "num_pipeline = Pipeline(steps=[('impute_num', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
        "                               ('scale_num', StandardScaler())])"
      ],
      "metadata": {
        "id": "5UcB7QE9-tSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#establish preprocessing pipeline by columns\n",
        "preproc = ColumnTransformer([('cat_pipe', cat_pipeline, make_column_selector(dtype_include=object)),\n",
        "                             ('num_pipe', num_pipeline, make_column_selector(dtype_include=np.number))],\n",
        "                             remainder='passthrough')"
      ],
      "metadata": {
        "id": "q8cduwXT-8Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate the whole modeling pipeline with preprocessing\n",
        "LRpipe = Pipeline(steps=[('preproc', preproc),\n",
        "                       ('mdl', LogisticRegression(penalty='elasticnet', solver='saga', tol=0.01))])\n",
        "\n",
        "#visualization for steps\n",
        "with config_context(display='diagram'):\n",
        "    display(LRpipe)"
      ],
      "metadata": {
        "id": "Al1cndn8_Bwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 5\n",
        "## Explore 3 different models in your ML pipeline for your personal project"
      ],
      "metadata": {
        "id": "OLeJE64Z_qwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Random Forest Pipeline\n",
        "randomForest_pipe = Pipeline(steps=[('preproc', preproc),\n",
        "                       ('mdl', RandomForestClassifier())])\n",
        "\n",
        "#visualization for steps\n",
        "with config_context(display='diagram'):\n",
        "    display(randomForest_pipe)\n",
        "\n",
        "# Set up Naive Bayes classifier for multinomial models\n",
        "naiveBayes_pipe = Pipeline(steps=[('preproc', preproc),\n",
        "                       ('mdl', MultinomialNB())])\n",
        "\n",
        "#visualization for steps\n",
        "with config_context(display='diagram'):\n",
        "    display(naiveBayes_pipe)"
      ],
      "metadata": {
        "id": "VqAiP4_Y_y7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation with Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "LL6nItvoBe8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up tuning grids\n",
        "logisticRegression_tuning_grid = {'mdl__l1_ratio' : np.linspace(0,1,5),\n",
        "               'mdl__C': np.logspace(-1, 6, 3) }\n",
        "\n",
        "randomForest_tuning_grid = {'mdl__n_estimators' : [100, 200 ,500],\n",
        "               'mdl__max_depth': [10, 15, 20] }\n",
        "\n",
        "NB_tuning_grid = RepeatedStratifiedKFold(n_splits=5,  n_repeats=3, random_state=999)"
      ],
      "metadata": {
        "id": "L0ZVdPvsBbZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the models\n",
        "#logisticRegression_grid_search = GridSearchCV(LRpipe, param_grid = logisticRegression_tuning_grid, cv = 5, return_train_score=True)\n",
        "#logisticRegression_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Now let's do the Random Forest Classifier\n",
        "#randomForest_grid_search = GridSearchCV(randomForest_pipe, param_grid = randomForest_tuning_grid, cv = 5, return_train_score=True)\n",
        "#randomForest_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Now let's do the Random Forest Classifier\n",
        "#NB_grid_search = GridSearchCV(naiveBayes_pipe, param_grid = NB_tuning_grid, cv = 5, return_train_score=True)\n",
        "#NB_grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "wYESBg8ZdcYA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}